{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702a648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calculo3/anaconda3/envs/pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch import nn, optim\n",
    "import time\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score,precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fa65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed_all(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718c6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet18, resnet34, resnet50, alexnet, vgg11_bn, vgg11, squeezenet, densenet, inception]\n",
    "model_name = \"densenet121\"\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "# Number of epochs to train for \n",
    "num_epochs = 75\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5fef88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6cda04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = \"\"\n",
    "VALID_DIR = \"\"\n",
    "BATCH_SIZE = 24\n",
    "# Transforms\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "# Load data and create dataloaders\n",
    "train_dataset = torchvision.datasets.ImageFolder(root=TRAIN_DIR, transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root=VALID_DIR, transform=data_transforms)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_feat_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_feat_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f73702a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    return acc\n",
    "\n",
    "def f1score(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    y_test2 = y_test.cpu().detach().numpy()\n",
    "    y_pred_tag2 = y_pred_tag.cpu().detach().numpy()\n",
    "    f1 = f1_score(y_test2, y_pred_tag2, average ='binary')\n",
    "    return f1\n",
    "\n",
    "def precision(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    y_test2 = y_test.cpu().detach().numpy()\n",
    "    y_pred_tag2 = y_pred_tag.cpu().detach().numpy())\n",
    "    precision = precision_score(y_test2, y_pred_tag2, average ='binary')\n",
    "    return precision\n",
    "\n",
    "def recall(y_pred, y_test, matrix):\n",
    "    y_pred_tag = torch.round(y_pred)\n",
    "    y_test2 = y_test.cpu().detach().numpy()\n",
    "    y_pred_tag2 = y_pred_tag.cpu().detach().numpy()\n",
    "    recall_sc = recall_score(y_test2, y_pred_tag2, average ='binary')\n",
    "    return recall_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f0c2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True #Retrain all model layers\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False #fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db4d47a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision.models import alexnet\n",
    "from torchvision.models import vgg16_bn\n",
    "from torchvision.models import densenet121\n",
    "from torchvision.models import squeezenet1_0\n",
    "\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet18\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = resnet18(weights=None)#.pretrained=use_pretrained\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, num_classes),   # Cambiamos la capa final a una salida de 1 nodo\n",
    "            nn.Softmax(1)                  # Agregamos la activaci√≥n sigmoide\n",
    "        )\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet34\":\n",
    "        \"\"\" Resnet34\n",
    "        \"\"\"\n",
    "        model_ft= models.resnet34(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "\n",
    "        input_size = 224    \n",
    "        \n",
    "    elif model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224  \n",
    "        \n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(weights = 'IMAGENET1K_V1')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg11_bn\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224\n",
    "    elif model_name == \"vgg11\":\n",
    "        \"\"\" VGG11\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224        \n",
    "    elif model_name == \"vgg13_bn\":\n",
    "        \"\"\" VGG13_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg13_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224       \n",
    "    elif model_name == \"vgg13\":\n",
    "        \"\"\" VGG13\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg13(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224  \n",
    "    elif model_name == \"vgg16_bn\":\n",
    "        \"\"\" VGG16_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16_bn(weights = None) #weights=None#pretrained=use_pretrained\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224          \n",
    "    elif model_name == \"vgg16\":\n",
    "        \"\"\" VGG16\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224  \n",
    "    elif model_name == \"vgg19\":\n",
    "        \"\"\" VGG19\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg19(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224         \n",
    "    elif model_name == \"vgg19_bn\":\n",
    "        \"\"\" VGG19_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224          \n",
    "    elif model_name == \"squeezenet10\":\n",
    "        \"\"\" Squeezenet10\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(weights = 'IMAGENET1K_V1')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        #model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224\n",
    "    elif model_name == \"squeezenet11\":\n",
    "        \"\"\" Squeezenet11\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "        input_size = 224        \n",
    "\n",
    "    elif model_name == \"densenet121\":\n",
    "        \"\"\" Densenet 121 \n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(weights = 'IMAGENET1K_V1')#\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.classifier.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.4, training=m.training))\n",
    "\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"densenet161\":\n",
    "        \"\"\" Densenet 161 \n",
    "        \"\"\"\n",
    "        model_ft = models.densenet161(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "    elif model_name == \"densenet169\":\n",
    "        \"\"\" Densenet 169\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet169(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "    elif model_name == \"densenet201\":\n",
    "        \"\"\" Densenet 201\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet201(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224        \n",
    "    \n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95fa1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_history = []\n",
    "val_recall_history = []\n",
    "train_acc_history = []\n",
    "val_f1_history = []\n",
    "train_f1_history= []\n",
    "train_loss_history= []\n",
    "val_loss_history= []\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        preds_all_train = torch.tensor([],dtype = torch.float32)\n",
    "        labels_all_train = torch.tensor([],dtype = torch.float32)\n",
    "        preds_all_train = preds_all_train.to(\"cpu\")\n",
    "        labels_all_train = labels_all_train.to(\"cpu\")\n",
    "\n",
    "        preds_all_val = torch.tensor([],dtype = torch.float32)\n",
    "        labels_all_val = torch.tensor([],dtype = torch.float32)\n",
    "        preds_all_val = preds_all_val.to(\"cpu\")\n",
    "        labels_all_val = labels_all_val.to(\"cpu\")\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            \n",
    "            \n",
    "            if phase == 'train':\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                dataloader = val_loader\n",
    "            for inputs, labels in dataloader:                \n",
    "                if phase == 'train':\n",
    "                    labels_all_train = torch.cat((labels_all_train, labels), 0)\n",
    "                else:\n",
    "                    labels_all_val = torch.cat((labels_all_val, labels), 0)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "        \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                   \n",
    "                    preds= preds.to(\"cpu\")\n",
    "                    if phase == 'train':\n",
    "                        preds_all_train = torch.cat((preds_all_train, preds), 0)\n",
    "                    else:\n",
    "                        preds_all_val = torch.cat((preds_all_val, preds), 0)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                labels= labels.to(\"cpu\")\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "            if phase == 'train':\n",
    "                acc_train = binary_acc(preds_all_train, labels_all_train)\n",
    "                train_acc_history.append(acc_train)\n",
    "                f1_train = f1score(preds_all_train, labels_all_train)\n",
    "                train_f1_history.append(f1_train)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                precision_train = precision(preds_all_train, labels_all_train)\n",
    "                recall_train = recall(preds_all_train, labels_all_train, True)\n",
    "                tn, fp, fn, tp = confusion_matrix(labels_all_train, preds_all_train).ravel()\n",
    "                print(phase)\n",
    "                print(\"acc: \", acc_train, \"f1: \", f1_train, \"recall: \", recall_train, \"precision: \", precision_train)\n",
    "                print(\"tn: \", tn, \"fp: \", fp, \"fn: \", fn, \"tp: \", tp)\n",
    "            else:\n",
    "                acc_val = binary_acc(preds_all_val, labels_all_val)\n",
    "                f1_val = f1score(preds_all_val, labels_all_val)\n",
    "                precision_val = precision(preds_all_val, labels_all_val)\n",
    "                recall_val = recall(preds_all_val, labels_all_val, True)\n",
    "                tn, fp, fn, tp = confusion_matrix(labels_all_val, preds_all_val).ravel()\n",
    "                print(\"acc: \", acc_val, \"f1: \", f1_val, \"recall: \", recall_val, \"precision: \", precision_val)\n",
    "                print(\"tn: \", tn, \"fp: \", fp, \"fn: \", fn, \"tp: \", tp)\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and f1_val > best_acc:\n",
    "                best_acc = f1_val\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "            if phase == 'val':\n",
    "                val_recall_history.append(recall_val)\n",
    "                val_acc_history.append(acc_val)\n",
    "                val_f1_history.append(f1_val)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val f1: {:4f}'.format(best_acc))\n",
    "    print('Best epoch: {:4f}'.format(best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c44ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.conv0.weight\n",
      "\t features.norm0.weight\n",
      "\t features.norm0.bias\n",
      "\t features.denseblock1.denselayer1.norm1.weight\n",
      "\t features.denseblock1.denselayer1.norm1.bias\n",
      "\t features.denseblock1.denselayer1.conv1.weight\n",
      "\t features.denseblock1.denselayer1.norm2.weight\n",
      "\t features.denseblock1.denselayer1.norm2.bias\n",
      "\t features.denseblock1.denselayer1.conv2.weight\n",
      "\t features.denseblock1.denselayer2.norm1.weight\n",
      "\t features.denseblock1.denselayer2.norm1.bias\n",
      "\t features.denseblock1.denselayer2.conv1.weight\n",
      "\t features.denseblock1.denselayer2.norm2.weight\n",
      "\t features.denseblock1.denselayer2.norm2.bias\n",
      "\t features.denseblock1.denselayer2.conv2.weight\n",
      "\t features.denseblock1.denselayer3.norm1.weight\n",
      "\t features.denseblock1.denselayer3.norm1.bias\n",
      "\t features.denseblock1.denselayer3.conv1.weight\n",
      "\t features.denseblock1.denselayer3.norm2.weight\n",
      "\t features.denseblock1.denselayer3.norm2.bias\n",
      "\t features.denseblock1.denselayer3.conv2.weight\n",
      "\t features.denseblock1.denselayer4.norm1.weight\n",
      "\t features.denseblock1.denselayer4.norm1.bias\n",
      "\t features.denseblock1.denselayer4.conv1.weight\n",
      "\t features.denseblock1.denselayer4.norm2.weight\n",
      "\t features.denseblock1.denselayer4.norm2.bias\n",
      "\t features.denseblock1.denselayer4.conv2.weight\n",
      "\t features.denseblock1.denselayer5.norm1.weight\n",
      "\t features.denseblock1.denselayer5.norm1.bias\n",
      "\t features.denseblock1.denselayer5.conv1.weight\n",
      "\t features.denseblock1.denselayer5.norm2.weight\n",
      "\t features.denseblock1.denselayer5.norm2.bias\n",
      "\t features.denseblock1.denselayer5.conv2.weight\n",
      "\t features.denseblock1.denselayer6.norm1.weight\n",
      "\t features.denseblock1.denselayer6.norm1.bias\n",
      "\t features.denseblock1.denselayer6.conv1.weight\n",
      "\t features.denseblock1.denselayer6.norm2.weight\n",
      "\t features.denseblock1.denselayer6.norm2.bias\n",
      "\t features.denseblock1.denselayer6.conv2.weight\n",
      "\t features.transition1.norm.weight\n",
      "\t features.transition1.norm.bias\n",
      "\t features.transition1.conv.weight\n",
      "\t features.denseblock2.denselayer1.norm1.weight\n",
      "\t features.denseblock2.denselayer1.norm1.bias\n",
      "\t features.denseblock2.denselayer1.conv1.weight\n",
      "\t features.denseblock2.denselayer1.norm2.weight\n",
      "\t features.denseblock2.denselayer1.norm2.bias\n",
      "\t features.denseblock2.denselayer1.conv2.weight\n",
      "\t features.denseblock2.denselayer2.norm1.weight\n",
      "\t features.denseblock2.denselayer2.norm1.bias\n",
      "\t features.denseblock2.denselayer2.conv1.weight\n",
      "\t features.denseblock2.denselayer2.norm2.weight\n",
      "\t features.denseblock2.denselayer2.norm2.bias\n",
      "\t features.denseblock2.denselayer2.conv2.weight\n",
      "\t features.denseblock2.denselayer3.norm1.weight\n",
      "\t features.denseblock2.denselayer3.norm1.bias\n",
      "\t features.denseblock2.denselayer3.conv1.weight\n",
      "\t features.denseblock2.denselayer3.norm2.weight\n",
      "\t features.denseblock2.denselayer3.norm2.bias\n",
      "\t features.denseblock2.denselayer3.conv2.weight\n",
      "\t features.denseblock2.denselayer4.norm1.weight\n",
      "\t features.denseblock2.denselayer4.norm1.bias\n",
      "\t features.denseblock2.denselayer4.conv1.weight\n",
      "\t features.denseblock2.denselayer4.norm2.weight\n",
      "\t features.denseblock2.denselayer4.norm2.bias\n",
      "\t features.denseblock2.denselayer4.conv2.weight\n",
      "\t features.denseblock2.denselayer5.norm1.weight\n",
      "\t features.denseblock2.denselayer5.norm1.bias\n",
      "\t features.denseblock2.denselayer5.conv1.weight\n",
      "\t features.denseblock2.denselayer5.norm2.weight\n",
      "\t features.denseblock2.denselayer5.norm2.bias\n",
      "\t features.denseblock2.denselayer5.conv2.weight\n",
      "\t features.denseblock2.denselayer6.norm1.weight\n",
      "\t features.denseblock2.denselayer6.norm1.bias\n",
      "\t features.denseblock2.denselayer6.conv1.weight\n",
      "\t features.denseblock2.denselayer6.norm2.weight\n",
      "\t features.denseblock2.denselayer6.norm2.bias\n",
      "\t features.denseblock2.denselayer6.conv2.weight\n",
      "\t features.denseblock2.denselayer7.norm1.weight\n",
      "\t features.denseblock2.denselayer7.norm1.bias\n",
      "\t features.denseblock2.denselayer7.conv1.weight\n",
      "\t features.denseblock2.denselayer7.norm2.weight\n",
      "\t features.denseblock2.denselayer7.norm2.bias\n",
      "\t features.denseblock2.denselayer7.conv2.weight\n",
      "\t features.denseblock2.denselayer8.norm1.weight\n",
      "\t features.denseblock2.denselayer8.norm1.bias\n",
      "\t features.denseblock2.denselayer8.conv1.weight\n",
      "\t features.denseblock2.denselayer8.norm2.weight\n",
      "\t features.denseblock2.denselayer8.norm2.bias\n",
      "\t features.denseblock2.denselayer8.conv2.weight\n",
      "\t features.denseblock2.denselayer9.norm1.weight\n",
      "\t features.denseblock2.denselayer9.norm1.bias\n",
      "\t features.denseblock2.denselayer9.conv1.weight\n",
      "\t features.denseblock2.denselayer9.norm2.weight\n",
      "\t features.denseblock2.denselayer9.norm2.bias\n",
      "\t features.denseblock2.denselayer9.conv2.weight\n",
      "\t features.denseblock2.denselayer10.norm1.weight\n",
      "\t features.denseblock2.denselayer10.norm1.bias\n",
      "\t features.denseblock2.denselayer10.conv1.weight\n",
      "\t features.denseblock2.denselayer10.norm2.weight\n",
      "\t features.denseblock2.denselayer10.norm2.bias\n",
      "\t features.denseblock2.denselayer10.conv2.weight\n",
      "\t features.denseblock2.denselayer11.norm1.weight\n",
      "\t features.denseblock2.denselayer11.norm1.bias\n",
      "\t features.denseblock2.denselayer11.conv1.weight\n",
      "\t features.denseblock2.denselayer11.norm2.weight\n",
      "\t features.denseblock2.denselayer11.norm2.bias\n",
      "\t features.denseblock2.denselayer11.conv2.weight\n",
      "\t features.denseblock2.denselayer12.norm1.weight\n",
      "\t features.denseblock2.denselayer12.norm1.bias\n",
      "\t features.denseblock2.denselayer12.conv1.weight\n",
      "\t features.denseblock2.denselayer12.norm2.weight\n",
      "\t features.denseblock2.denselayer12.norm2.bias\n",
      "\t features.denseblock2.denselayer12.conv2.weight\n",
      "\t features.transition2.norm.weight\n",
      "\t features.transition2.norm.bias\n",
      "\t features.transition2.conv.weight\n",
      "\t features.denseblock3.denselayer1.norm1.weight\n",
      "\t features.denseblock3.denselayer1.norm1.bias\n",
      "\t features.denseblock3.denselayer1.conv1.weight\n",
      "\t features.denseblock3.denselayer1.norm2.weight\n",
      "\t features.denseblock3.denselayer1.norm2.bias\n",
      "\t features.denseblock3.denselayer1.conv2.weight\n",
      "\t features.denseblock3.denselayer2.norm1.weight\n",
      "\t features.denseblock3.denselayer2.norm1.bias\n",
      "\t features.denseblock3.denselayer2.conv1.weight\n",
      "\t features.denseblock3.denselayer2.norm2.weight\n",
      "\t features.denseblock3.denselayer2.norm2.bias\n",
      "\t features.denseblock3.denselayer2.conv2.weight\n",
      "\t features.denseblock3.denselayer3.norm1.weight\n",
      "\t features.denseblock3.denselayer3.norm1.bias\n",
      "\t features.denseblock3.denselayer3.conv1.weight\n",
      "\t features.denseblock3.denselayer3.norm2.weight\n",
      "\t features.denseblock3.denselayer3.norm2.bias\n",
      "\t features.denseblock3.denselayer3.conv2.weight\n",
      "\t features.denseblock3.denselayer4.norm1.weight\n",
      "\t features.denseblock3.denselayer4.norm1.bias\n",
      "\t features.denseblock3.denselayer4.conv1.weight\n",
      "\t features.denseblock3.denselayer4.norm2.weight\n",
      "\t features.denseblock3.denselayer4.norm2.bias\n",
      "\t features.denseblock3.denselayer4.conv2.weight\n",
      "\t features.denseblock3.denselayer5.norm1.weight\n",
      "\t features.denseblock3.denselayer5.norm1.bias\n",
      "\t features.denseblock3.denselayer5.conv1.weight\n",
      "\t features.denseblock3.denselayer5.norm2.weight\n",
      "\t features.denseblock3.denselayer5.norm2.bias\n",
      "\t features.denseblock3.denselayer5.conv2.weight\n",
      "\t features.denseblock3.denselayer6.norm1.weight\n",
      "\t features.denseblock3.denselayer6.norm1.bias\n",
      "\t features.denseblock3.denselayer6.conv1.weight\n",
      "\t features.denseblock3.denselayer6.norm2.weight\n",
      "\t features.denseblock3.denselayer6.norm2.bias\n",
      "\t features.denseblock3.denselayer6.conv2.weight\n",
      "\t features.denseblock3.denselayer7.norm1.weight\n",
      "\t features.denseblock3.denselayer7.norm1.bias\n",
      "\t features.denseblock3.denselayer7.conv1.weight\n",
      "\t features.denseblock3.denselayer7.norm2.weight\n",
      "\t features.denseblock3.denselayer7.norm2.bias\n",
      "\t features.denseblock3.denselayer7.conv2.weight\n",
      "\t features.denseblock3.denselayer8.norm1.weight\n",
      "\t features.denseblock3.denselayer8.norm1.bias\n",
      "\t features.denseblock3.denselayer8.conv1.weight\n",
      "\t features.denseblock3.denselayer8.norm2.weight\n",
      "\t features.denseblock3.denselayer8.norm2.bias\n",
      "\t features.denseblock3.denselayer8.conv2.weight\n",
      "\t features.denseblock3.denselayer9.norm1.weight\n",
      "\t features.denseblock3.denselayer9.norm1.bias\n",
      "\t features.denseblock3.denselayer9.conv1.weight\n",
      "\t features.denseblock3.denselayer9.norm2.weight\n",
      "\t features.denseblock3.denselayer9.norm2.bias\n",
      "\t features.denseblock3.denselayer9.conv2.weight\n",
      "\t features.denseblock3.denselayer10.norm1.weight\n",
      "\t features.denseblock3.denselayer10.norm1.bias\n",
      "\t features.denseblock3.denselayer10.conv1.weight\n",
      "\t features.denseblock3.denselayer10.norm2.weight\n",
      "\t features.denseblock3.denselayer10.norm2.bias\n",
      "\t features.denseblock3.denselayer10.conv2.weight\n",
      "\t features.denseblock3.denselayer11.norm1.weight\n",
      "\t features.denseblock3.denselayer11.norm1.bias\n",
      "\t features.denseblock3.denselayer11.conv1.weight\n",
      "\t features.denseblock3.denselayer11.norm2.weight\n",
      "\t features.denseblock3.denselayer11.norm2.bias\n",
      "\t features.denseblock3.denselayer11.conv2.weight\n",
      "\t features.denseblock3.denselayer12.norm1.weight\n",
      "\t features.denseblock3.denselayer12.norm1.bias\n",
      "\t features.denseblock3.denselayer12.conv1.weight\n",
      "\t features.denseblock3.denselayer12.norm2.weight\n",
      "\t features.denseblock3.denselayer12.norm2.bias\n",
      "\t features.denseblock3.denselayer12.conv2.weight\n",
      "\t features.denseblock3.denselayer13.norm1.weight\n",
      "\t features.denseblock3.denselayer13.norm1.bias\n",
      "\t features.denseblock3.denselayer13.conv1.weight\n",
      "\t features.denseblock3.denselayer13.norm2.weight\n",
      "\t features.denseblock3.denselayer13.norm2.bias\n",
      "\t features.denseblock3.denselayer13.conv2.weight\n",
      "\t features.denseblock3.denselayer14.norm1.weight\n",
      "\t features.denseblock3.denselayer14.norm1.bias\n",
      "\t features.denseblock3.denselayer14.conv1.weight\n",
      "\t features.denseblock3.denselayer14.norm2.weight\n",
      "\t features.denseblock3.denselayer14.norm2.bias\n",
      "\t features.denseblock3.denselayer14.conv2.weight\n",
      "\t features.denseblock3.denselayer15.norm1.weight\n",
      "\t features.denseblock3.denselayer15.norm1.bias\n",
      "\t features.denseblock3.denselayer15.conv1.weight\n",
      "\t features.denseblock3.denselayer15.norm2.weight\n",
      "\t features.denseblock3.denselayer15.norm2.bias\n",
      "\t features.denseblock3.denselayer15.conv2.weight\n",
      "\t features.denseblock3.denselayer16.norm1.weight\n",
      "\t features.denseblock3.denselayer16.norm1.bias\n",
      "\t features.denseblock3.denselayer16.conv1.weight\n",
      "\t features.denseblock3.denselayer16.norm2.weight\n",
      "\t features.denseblock3.denselayer16.norm2.bias\n",
      "\t features.denseblock3.denselayer16.conv2.weight\n",
      "\t features.denseblock3.denselayer17.norm1.weight\n",
      "\t features.denseblock3.denselayer17.norm1.bias\n",
      "\t features.denseblock3.denselayer17.conv1.weight\n",
      "\t features.denseblock3.denselayer17.norm2.weight\n",
      "\t features.denseblock3.denselayer17.norm2.bias\n",
      "\t features.denseblock3.denselayer17.conv2.weight\n",
      "\t features.denseblock3.denselayer18.norm1.weight\n",
      "\t features.denseblock3.denselayer18.norm1.bias\n",
      "\t features.denseblock3.denselayer18.conv1.weight\n",
      "\t features.denseblock3.denselayer18.norm2.weight\n",
      "\t features.denseblock3.denselayer18.norm2.bias\n",
      "\t features.denseblock3.denselayer18.conv2.weight\n",
      "\t features.denseblock3.denselayer19.norm1.weight\n",
      "\t features.denseblock3.denselayer19.norm1.bias\n",
      "\t features.denseblock3.denselayer19.conv1.weight\n",
      "\t features.denseblock3.denselayer19.norm2.weight\n",
      "\t features.denseblock3.denselayer19.norm2.bias\n",
      "\t features.denseblock3.denselayer19.conv2.weight\n",
      "\t features.denseblock3.denselayer20.norm1.weight\n",
      "\t features.denseblock3.denselayer20.norm1.bias\n",
      "\t features.denseblock3.denselayer20.conv1.weight\n",
      "\t features.denseblock3.denselayer20.norm2.weight\n",
      "\t features.denseblock3.denselayer20.norm2.bias\n",
      "\t features.denseblock3.denselayer20.conv2.weight\n",
      "\t features.denseblock3.denselayer21.norm1.weight\n",
      "\t features.denseblock3.denselayer21.norm1.bias\n",
      "\t features.denseblock3.denselayer21.conv1.weight\n",
      "\t features.denseblock3.denselayer21.norm2.weight\n",
      "\t features.denseblock3.denselayer21.norm2.bias\n",
      "\t features.denseblock3.denselayer21.conv2.weight\n",
      "\t features.denseblock3.denselayer22.norm1.weight\n",
      "\t features.denseblock3.denselayer22.norm1.bias\n",
      "\t features.denseblock3.denselayer22.conv1.weight\n",
      "\t features.denseblock3.denselayer22.norm2.weight\n",
      "\t features.denseblock3.denselayer22.norm2.bias\n",
      "\t features.denseblock3.denselayer22.conv2.weight\n",
      "\t features.denseblock3.denselayer23.norm1.weight\n",
      "\t features.denseblock3.denselayer23.norm1.bias\n",
      "\t features.denseblock3.denselayer23.conv1.weight\n",
      "\t features.denseblock3.denselayer23.norm2.weight\n",
      "\t features.denseblock3.denselayer23.norm2.bias\n",
      "\t features.denseblock3.denselayer23.conv2.weight\n",
      "\t features.denseblock3.denselayer24.norm1.weight\n",
      "\t features.denseblock3.denselayer24.norm1.bias\n",
      "\t features.denseblock3.denselayer24.conv1.weight\n",
      "\t features.denseblock3.denselayer24.norm2.weight\n",
      "\t features.denseblock3.denselayer24.norm2.bias\n",
      "\t features.denseblock3.denselayer24.conv2.weight\n",
      "\t features.transition3.norm.weight\n",
      "\t features.transition3.norm.bias\n",
      "\t features.transition3.conv.weight\n",
      "\t features.denseblock4.denselayer1.norm1.weight\n",
      "\t features.denseblock4.denselayer1.norm1.bias\n",
      "\t features.denseblock4.denselayer1.conv1.weight\n",
      "\t features.denseblock4.denselayer1.norm2.weight\n",
      "\t features.denseblock4.denselayer1.norm2.bias\n",
      "\t features.denseblock4.denselayer1.conv2.weight\n",
      "\t features.denseblock4.denselayer2.norm1.weight\n",
      "\t features.denseblock4.denselayer2.norm1.bias\n",
      "\t features.denseblock4.denselayer2.conv1.weight\n",
      "\t features.denseblock4.denselayer2.norm2.weight\n",
      "\t features.denseblock4.denselayer2.norm2.bias\n",
      "\t features.denseblock4.denselayer2.conv2.weight\n",
      "\t features.denseblock4.denselayer3.norm1.weight\n",
      "\t features.denseblock4.denselayer3.norm1.bias\n",
      "\t features.denseblock4.denselayer3.conv1.weight\n",
      "\t features.denseblock4.denselayer3.norm2.weight\n",
      "\t features.denseblock4.denselayer3.norm2.bias\n",
      "\t features.denseblock4.denselayer3.conv2.weight\n",
      "\t features.denseblock4.denselayer4.norm1.weight\n",
      "\t features.denseblock4.denselayer4.norm1.bias\n",
      "\t features.denseblock4.denselayer4.conv1.weight\n",
      "\t features.denseblock4.denselayer4.norm2.weight\n",
      "\t features.denseblock4.denselayer4.norm2.bias\n",
      "\t features.denseblock4.denselayer4.conv2.weight\n",
      "\t features.denseblock4.denselayer5.norm1.weight\n",
      "\t features.denseblock4.denselayer5.norm1.bias\n",
      "\t features.denseblock4.denselayer5.conv1.weight\n",
      "\t features.denseblock4.denselayer5.norm2.weight\n",
      "\t features.denseblock4.denselayer5.norm2.bias\n",
      "\t features.denseblock4.denselayer5.conv2.weight\n",
      "\t features.denseblock4.denselayer6.norm1.weight\n",
      "\t features.denseblock4.denselayer6.norm1.bias\n",
      "\t features.denseblock4.denselayer6.conv1.weight\n",
      "\t features.denseblock4.denselayer6.norm2.weight\n",
      "\t features.denseblock4.denselayer6.norm2.bias\n",
      "\t features.denseblock4.denselayer6.conv2.weight\n",
      "\t features.denseblock4.denselayer7.norm1.weight\n",
      "\t features.denseblock4.denselayer7.norm1.bias\n",
      "\t features.denseblock4.denselayer7.conv1.weight\n",
      "\t features.denseblock4.denselayer7.norm2.weight\n",
      "\t features.denseblock4.denselayer7.norm2.bias\n",
      "\t features.denseblock4.denselayer7.conv2.weight\n",
      "\t features.denseblock4.denselayer8.norm1.weight\n",
      "\t features.denseblock4.denselayer8.norm1.bias\n",
      "\t features.denseblock4.denselayer8.conv1.weight\n",
      "\t features.denseblock4.denselayer8.norm2.weight\n",
      "\t features.denseblock4.denselayer8.norm2.bias\n",
      "\t features.denseblock4.denselayer8.conv2.weight\n",
      "\t features.denseblock4.denselayer9.norm1.weight\n",
      "\t features.denseblock4.denselayer9.norm1.bias\n",
      "\t features.denseblock4.denselayer9.conv1.weight\n",
      "\t features.denseblock4.denselayer9.norm2.weight\n",
      "\t features.denseblock4.denselayer9.norm2.bias\n",
      "\t features.denseblock4.denselayer9.conv2.weight\n",
      "\t features.denseblock4.denselayer10.norm1.weight\n",
      "\t features.denseblock4.denselayer10.norm1.bias\n",
      "\t features.denseblock4.denselayer10.conv1.weight\n",
      "\t features.denseblock4.denselayer10.norm2.weight\n",
      "\t features.denseblock4.denselayer10.norm2.bias\n",
      "\t features.denseblock4.denselayer10.conv2.weight\n",
      "\t features.denseblock4.denselayer11.norm1.weight\n",
      "\t features.denseblock4.denselayer11.norm1.bias\n",
      "\t features.denseblock4.denselayer11.conv1.weight\n",
      "\t features.denseblock4.denselayer11.norm2.weight\n",
      "\t features.denseblock4.denselayer11.norm2.bias\n",
      "\t features.denseblock4.denselayer11.conv2.weight\n",
      "\t features.denseblock4.denselayer12.norm1.weight\n",
      "\t features.denseblock4.denselayer12.norm1.bias\n",
      "\t features.denseblock4.denselayer12.conv1.weight\n",
      "\t features.denseblock4.denselayer12.norm2.weight\n",
      "\t features.denseblock4.denselayer12.norm2.bias\n",
      "\t features.denseblock4.denselayer12.conv2.weight\n",
      "\t features.denseblock4.denselayer13.norm1.weight\n",
      "\t features.denseblock4.denselayer13.norm1.bias\n",
      "\t features.denseblock4.denselayer13.conv1.weight\n",
      "\t features.denseblock4.denselayer13.norm2.weight\n",
      "\t features.denseblock4.denselayer13.norm2.bias\n",
      "\t features.denseblock4.denselayer13.conv2.weight\n",
      "\t features.denseblock4.denselayer14.norm1.weight\n",
      "\t features.denseblock4.denselayer14.norm1.bias\n",
      "\t features.denseblock4.denselayer14.conv1.weight\n",
      "\t features.denseblock4.denselayer14.norm2.weight\n",
      "\t features.denseblock4.denselayer14.norm2.bias\n",
      "\t features.denseblock4.denselayer14.conv2.weight\n",
      "\t features.denseblock4.denselayer15.norm1.weight\n",
      "\t features.denseblock4.denselayer15.norm1.bias\n",
      "\t features.denseblock4.denselayer15.conv1.weight\n",
      "\t features.denseblock4.denselayer15.norm2.weight\n",
      "\t features.denseblock4.denselayer15.norm2.bias\n",
      "\t features.denseblock4.denselayer15.conv2.weight\n",
      "\t features.denseblock4.denselayer16.norm1.weight\n",
      "\t features.denseblock4.denselayer16.norm1.bias\n",
      "\t features.denseblock4.denselayer16.conv1.weight\n",
      "\t features.denseblock4.denselayer16.norm2.weight\n",
      "\t features.denseblock4.denselayer16.norm2.bias\n",
      "\t features.denseblock4.denselayer16.conv2.weight\n",
      "\t features.norm5.weight\n",
      "\t features.norm5.bias\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0001, momentum =0.9)\n",
    "#optimizer_ft = optim.Adam(params_to_update, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d18392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#summary(model_ft, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f08ff950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.6486) f1:  0.35101253616200584 recall:  0.2559774964838256 precision:  0.558282208588957\n",
      "tn:  1060 fp:  144 fn:  529 tp:  182\n",
      "train Loss: 0.6280 Acc: 0.6486\n",
      "acc:  tensor(0.7143) f1:  0.4507042253521127 recall:  0.31683168316831684 precision:  0.7804878048780488\n",
      "tn:  163 fp:  9 fn:  69 tp:  32\n",
      "val Loss: 0.5594 Acc: 0.7143\n",
      "Epoch 1/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.7713) f1:  0.6217616580310882 recall:  0.5063291139240507 precision:  0.8053691275167785\n",
      "tn:  1117 fp:  87 fn:  351 tp:  360\n",
      "train Loss: 0.5223 Acc: 0.7713\n",
      "acc:  tensor(0.7985) f1:  0.6927374301675977 recall:  0.6138613861386139 precision:  0.7948717948717948\n",
      "tn:  156 fp:  16 fn:  39 tp:  62\n",
      "val Loss: 0.4895 Acc: 0.7985\n",
      "Epoch 2/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.7984) f1:  0.6897106109324759 recall:  0.6033755274261603 precision:  0.8048780487804879\n",
      "tn:  1100 fp:  104 fn:  282 tp:  429\n",
      "train Loss: 0.4564 Acc: 0.7984\n",
      "acc:  tensor(0.8132) f1:  0.7329842931937172 recall:  0.693069306930693 precision:  0.7777777777777778\n",
      "tn:  152 fp:  20 fn:  31 tp:  70\n",
      "val Loss: 0.4349 Acc: 0.8132\n",
      "Epoch 3/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8131) f1:  0.7154213036565978 recall:  0.6329113924050633 precision:  0.8226691042047533\n",
      "tn:  1107 fp:  97 fn:  261 tp:  450\n",
      "train Loss: 0.4200 Acc: 0.8131\n",
      "acc:  tensor(0.8205) f1:  0.7379679144385027 recall:  0.6831683168316832 precision:  0.8023255813953488\n",
      "tn:  155 fp:  17 fn:  32 tp:  69\n",
      "val Loss: 0.4095 Acc: 0.8205\n",
      "Epoch 4/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8251) f1:  0.7317854283426742 recall:  0.6427566807313643 precision:  0.8494423791821561\n",
      "tn:  1123 fp:  81 fn:  254 tp:  457\n",
      "train Loss: 0.3955 Acc: 0.8251\n",
      "acc:  tensor(0.8242) f1:  0.7473684210526316 recall:  0.7029702970297029 precision:  0.797752808988764\n",
      "tn:  154 fp:  18 fn:  30 tp:  71\n",
      "val Loss: 0.3902 Acc: 0.8242\n",
      "Epoch 5/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8381) f1:  0.7570532915360502 recall:  0.679324894514768 precision:  0.8548672566371681\n",
      "tn:  1122 fp:  82 fn:  228 tp:  483\n",
      "train Loss: 0.3751 Acc: 0.8381\n",
      "acc:  tensor(0.8315) f1:  0.7553191489361702 recall:  0.7029702970297029 precision:  0.8160919540229885\n",
      "tn:  156 fp:  16 fn:  30 tp:  71\n",
      "val Loss: 0.3852 Acc: 0.8315\n",
      "Epoch 6/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8590) f1:  0.7893915756630265 recall:  0.7116736990154712 precision:  0.8861646234676007\n",
      "tn:  1139 fp:  65 fn:  205 tp:  506\n",
      "train Loss: 0.3359 Acc: 0.8590\n",
      "acc:  tensor(0.8278) f1:  0.7614213197969543 recall:  0.7425742574257426 precision:  0.78125\n",
      "tn:  151 fp:  21 fn:  26 tp:  75\n",
      "val Loss: 0.3606 Acc: 0.8278\n",
      "Epoch 7/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8757) f1:  0.816358024691358 recall:  0.7440225035161744 precision:  0.9042735042735043\n",
      "tn:  1148 fp:  56 fn:  182 tp:  529\n",
      "train Loss: 0.3118 Acc: 0.8757\n",
      "acc:  tensor(0.8462) f1:  0.7857142857142857 recall:  0.7623762376237624 precision:  0.8105263157894737\n",
      "tn:  154 fp:  18 fn:  24 tp:  77\n",
      "val Loss: 0.3653 Acc: 0.8462\n",
      "Epoch 8/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8877) f1:  0.8367501898253606 recall:  0.7749648382559775 precision:  0.9092409240924092\n",
      "tn:  1149 fp:  55 fn:  160 tp:  551\n",
      "train Loss: 0.2856 Acc: 0.8877\n",
      "acc:  tensor(0.8242) f1:  0.7176470588235294 recall:  0.6039603960396039 precision:  0.8840579710144928\n",
      "tn:  164 fp:  8 fn:  40 tp:  61\n",
      "val Loss: 0.3905 Acc: 0.8242\n",
      "Epoch 9/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8919) f1:  0.8406466512702078 recall:  0.7679324894514767 precision:  0.9285714285714286\n",
      "tn:  1162 fp:  42 fn:  165 tp:  546\n",
      "train Loss: 0.2670 Acc: 0.8919\n",
      "acc:  tensor(0.8498) f1:  0.7918781725888325 recall:  0.7722772277227723 precision:  0.8125\n",
      "tn:  154 fp:  18 fn:  23 tp:  78\n",
      "val Loss: 0.3635 Acc: 0.8498\n",
      "Epoch 10/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.8940) f1:  0.8430007733952048 recall:  0.7665260196905767 precision:  0.936426116838488\n",
      "tn:  1167 fp:  37 fn:  166 tp:  545\n",
      "train Loss: 0.2566 Acc: 0.8940\n",
      "acc:  tensor(0.8388) f1:  0.7884615384615384 recall:  0.8118811881188119 precision:  0.7663551401869159\n",
      "tn:  147 fp:  25 fn:  19 tp:  82\n",
      "val Loss: 0.3810 Acc: 0.8388\n",
      "Epoch 11/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9117) f1:  0.8712871287128713 recall:  0.8045007032348804 precision:  0.9501661129568106\n",
      "tn:  1174 fp:  30 fn:  139 tp:  572\n",
      "train Loss: 0.2341 Acc: 0.9117\n",
      "acc:  tensor(0.8645) f1:  0.8042328042328043 recall:  0.7524752475247525 precision:  0.8636363636363636\n",
      "tn:  160 fp:  12 fn:  25 tp:  76\n",
      "val Loss: 0.3464 Acc: 0.8645\n",
      "Epoch 12/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9117) f1:  0.8694980694980695 recall:  0.7918424753867792 precision:  0.964041095890411\n",
      "tn:  1183 fp:  21 fn:  148 tp:  563\n",
      "train Loss: 0.2330 Acc: 0.9117\n",
      "acc:  tensor(0.8571) f1:  0.7936507936507936 recall:  0.7425742574257426 precision:  0.8522727272727273\n",
      "tn:  159 fp:  13 fn:  26 tp:  75\n",
      "val Loss: 0.3499 Acc: 0.8571\n",
      "Epoch 13/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9154) f1:  0.8757668711656442 recall:  0.8030942334739803 precision:  0.9629005059021922\n",
      "tn:  1182 fp:  22 fn:  140 tp:  571\n",
      "train Loss: 0.2194 Acc: 0.9154\n",
      "acc:  tensor(0.8388) f1:  0.7500000000000001 recall:  0.6534653465346535 precision:  0.88\n",
      "tn:  163 fp:  9 fn:  35 tp:  66\n",
      "val Loss: 0.3737 Acc: 0.8388\n",
      "Epoch 14/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9227) f1:  0.8865030674846626 recall:  0.8129395218002813 precision:  0.9747048903878583\n",
      "tn:  1189 fp:  15 fn:  133 tp:  578\n",
      "train Loss: 0.2048 Acc: 0.9227\n",
      "acc:  tensor(0.8645) f1:  0.8082901554404146 recall:  0.7722772277227723 precision:  0.8478260869565217\n",
      "tn:  158 fp:  14 fn:  23 tp:  78\n",
      "val Loss: 0.3498 Acc: 0.8645\n",
      "Epoch 15/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9258) f1:  0.891271056661562 recall:  0.8185654008438819 precision:  0.9781512605042016\n",
      "tn:  1191 fp:  13 fn:  129 tp:  582\n",
      "train Loss: 0.1966 Acc: 0.9258\n",
      "acc:  tensor(0.8755) f1:  0.8316831683168316 recall:  0.8316831683168316 precision:  0.8316831683168316\n",
      "tn:  155 fp:  17 fn:  17 tp:  84\n",
      "val Loss: 0.3591 Acc: 0.8755\n",
      "Epoch 16/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9117) f1:  0.868071818891491 recall:  0.7819971870604782 precision:  0.9754385964912281\n",
      "tn:  1190 fp:  14 fn:  155 tp:  556\n",
      "train Loss: 0.1967 Acc: 0.9117\n",
      "acc:  tensor(0.8645) f1:  0.8042328042328043 recall:  0.7524752475247525 precision:  0.8636363636363636\n",
      "tn:  160 fp:  12 fn:  25 tp:  76\n",
      "val Loss: 0.3566 Acc: 0.8645\n",
      "Epoch 17/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9285) f1:  0.8951798010711554 recall:  0.8227848101265823 precision:  0.9815436241610739\n",
      "tn:  1193 fp:  11 fn:  126 tp:  585\n",
      "train Loss: 0.1762 Acc: 0.9285\n",
      "acc:  tensor(0.8681) f1:  0.8125 recall:  0.7722772277227723 precision:  0.8571428571428571\n",
      "tn:  159 fp:  13 fn:  23 tp:  78\n",
      "val Loss: 0.3424 Acc: 0.8681\n",
      "Epoch 18/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9295) f1:  0.8959136468774094 recall:  0.8171589310829818 precision:  0.9914675767918089\n",
      "tn:  1199 fp:  5 fn:  130 tp:  581\n",
      "train Loss: 0.1679 Acc: 0.9295\n",
      "acc:  tensor(0.8608) f1:  0.8118811881188119 recall:  0.8118811881188119 precision:  0.8118811881188119\n",
      "tn:  153 fp:  19 fn:  19 tp:  82\n",
      "val Loss: 0.3576 Acc: 0.8608\n",
      "Epoch 19/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9274) f1:  0.8929946112394148 recall:  0.8157524613220816 precision:  0.9863945578231292\n",
      "tn:  1196 fp:  8 fn:  131 tp:  580\n",
      "train Loss: 0.1764 Acc: 0.9274\n",
      "acc:  tensor(0.8681) f1:  0.8125 recall:  0.7722772277227723 precision:  0.8571428571428571\n",
      "tn:  159 fp:  13 fn:  23 tp:  78\n",
      "val Loss: 0.3530 Acc: 0.8681\n",
      "Epoch 20/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9363) f1:  0.9071537290715372 recall:  0.8382559774964838 precision:  0.988391376451078\n",
      "tn:  1197 fp:  7 fn:  115 tp:  596\n",
      "train Loss: 0.1530 Acc: 0.9363\n",
      "acc:  tensor(0.8571) f1:  0.7999999999999999 recall:  0.7722772277227723 precision:  0.8297872340425532\n",
      "tn:  156 fp:  16 fn:  23 tp:  78\n",
      "val Loss: 0.3647 Acc: 0.8571\n",
      "Epoch 21/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9399) f1:  0.9125475285171102 recall:  0.8438818565400844 precision:  0.9933774834437086\n",
      "tn:  1200 fp:  4 fn:  111 tp:  600\n",
      "train Loss: 0.1603 Acc: 0.9399\n",
      "acc:  tensor(0.8645) f1:  0.8 recall:  0.7326732673267327 precision:  0.8809523809523809\n",
      "tn:  162 fp:  10 fn:  27 tp:  74\n",
      "val Loss: 0.3738 Acc: 0.8645\n",
      "Epoch 22/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9352) f1:  0.9051987767584099 recall:  0.8326300984528833 precision:  0.9916247906197655\n",
      "tn:  1199 fp:  5 fn:  119 tp:  592\n",
      "train Loss: 0.1512 Acc: 0.9352\n",
      "acc:  tensor(0.8462) f1:  0.7835051546391754 recall:  0.7524752475247525 precision:  0.8172043010752689\n",
      "tn:  155 fp:  17 fn:  25 tp:  76\n",
      "val Loss: 0.3721 Acc: 0.8462\n",
      "Epoch 23/74\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "acc:  tensor(0.9248) f1:  0.8887171561051005 recall:  0.8087201125175809 precision:  0.9862778730703259\n",
      "tn:  1196 fp:  8 fn:  136 tp:  575\n",
      "train Loss: 0.1503 Acc: 0.9248\n",
      "acc:  tensor(0.8645) f1:  0.8042328042328043 recall:  0.7524752475247525 precision:  0.8636363636363636\n",
      "tn:  160 fp:  12 fn:  25 tp:  76\n",
      "val Loss: 0.3876 Acc: 0.8645\n",
      "Epoch 24/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9305) f1:  0.897138437741686 recall:  0.8157524613220816 precision:  0.9965635738831615\n",
      "tn:  1202 fp:  2 fn:  131 tp:  580\n",
      "train Loss: 0.1573 Acc: 0.9305\n",
      "acc:  tensor(0.8755) f1:  0.8210526315789473 recall:  0.7722772277227723 precision:  0.8764044943820225\n",
      "tn:  161 fp:  11 fn:  23 tp:  78\n",
      "val Loss: 0.3865 Acc: 0.8755\n",
      "Epoch 25/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9253) f1:  0.888888888888889 recall:  0.8045007032348804 precision:  0.9930555555555556\n",
      "tn:  1200 fp:  4 fn:  139 tp:  572\n",
      "train Loss: 0.1505 Acc: 0.9253\n",
      "acc:  tensor(0.8571) f1:  0.7891891891891892 recall:  0.7227722772277227 precision:  0.8690476190476191\n",
      "tn:  161 fp:  11 fn:  28 tp:  73\n",
      "val Loss: 0.4027 Acc: 0.8571\n",
      "Epoch 26/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9373) f1:  0.9078341013824885 recall:  0.8312236286919831 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  120 tp:  591\n",
      "train Loss: 0.1407 Acc: 0.9373\n",
      "acc:  tensor(0.8681) f1:  0.8064516129032258 recall:  0.7425742574257426 precision:  0.8823529411764706\n",
      "tn:  162 fp:  10 fn:  26 tp:  75\n",
      "val Loss: 0.4004 Acc: 0.8681\n",
      "Epoch 27/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9384) f1:  0.9099236641221373 recall:  0.8382559774964838 precision:  0.994991652754591\n",
      "tn:  1201 fp:  3 fn:  115 tp:  596\n",
      "train Loss: 0.1351 Acc: 0.9384\n",
      "acc:  tensor(0.8535) f1:  0.7916666666666667 recall:  0.7524752475247525 precision:  0.8351648351648352\n",
      "tn:  157 fp:  15 fn:  25 tp:  76\n",
      "val Loss: 0.4165 Acc: 0.8535\n",
      "Epoch 28/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9347) f1:  0.9040675364543361 recall:  0.8284106891701828 precision:  0.9949324324324325\n",
      "tn:  1201 fp:  3 fn:  122 tp:  589\n",
      "train Loss: 0.1489 Acc: 0.9347\n",
      "acc:  tensor(0.8718) f1:  0.8241206030150754 recall:  0.8118811881188119 precision:  0.8367346938775511\n",
      "tn:  156 fp:  16 fn:  19 tp:  82\n",
      "val Loss: 0.3730 Acc: 0.8718\n",
      "Epoch 29/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9446) f1:  0.9196969696969697 recall:  0.8537271448663853 precision:  0.9967159277504105\n",
      "tn:  1202 fp:  2 fn:  104 tp:  607\n",
      "train Loss: 0.1356 Acc: 0.9446\n",
      "acc:  tensor(0.8681) f1:  0.8064516129032258 recall:  0.7425742574257426 precision:  0.8823529411764706\n",
      "tn:  162 fp:  10 fn:  26 tp:  75\n",
      "val Loss: 0.4158 Acc: 0.8681\n",
      "Epoch 30/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9426) f1:  0.9162861491628614 recall:  0.8466947960618847 precision:  0.9983416252072969\n",
      "tn:  1203 fp:  1 fn:  109 tp:  602\n",
      "train Loss: 0.1275 Acc: 0.9426\n",
      "acc:  tensor(0.8645) f1:  0.8 recall:  0.7326732673267327 precision:  0.8809523809523809\n",
      "tn:  162 fp:  10 fn:  27 tp:  74\n",
      "val Loss: 0.4024 Acc: 0.8645\n",
      "Epoch 31/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9358) f1:  0.9057471264367816 recall:  0.8312236286919831 precision:  0.9949494949494949\n",
      "tn:  1201 fp:  3 fn:  120 tp:  591\n",
      "train Loss: 0.1386 Acc: 0.9358\n",
      "acc:  tensor(0.8755) f1:  0.8191489361702128 recall:  0.7623762376237624 precision:  0.8850574712643678\n",
      "tn:  162 fp:  10 fn:  24 tp:  77\n",
      "val Loss: 0.4135 Acc: 0.8755\n",
      "Epoch 32/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9452) f1:  0.9207547169811321 recall:  0.8579465541490858 precision:  0.993485342019544\n",
      "tn:  1200 fp:  4 fn:  101 tp:  610\n",
      "train Loss: 0.1282 Acc: 0.9452\n",
      "acc:  tensor(0.8571) f1:  0.7891891891891892 recall:  0.7227722772277227 precision:  0.8690476190476191\n",
      "tn:  161 fp:  11 fn:  28 tp:  73\n",
      "val Loss: 0.4341 Acc: 0.8571\n",
      "Epoch 33/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9436) f1:  0.9180576631259484 recall:  0.8509142053445851 precision:  0.9967051070840197\n",
      "tn:  1202 fp:  2 fn:  106 tp:  605\n",
      "train Loss: 0.1247 Acc: 0.9436\n",
      "acc:  tensor(0.8828) f1:  0.84 recall:  0.8316831683168316 precision:  0.8484848484848485\n",
      "tn:  157 fp:  15 fn:  17 tp:  84\n",
      "val Loss: 0.3888 Acc: 0.8828\n",
      "Epoch 34/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9452) f1:  0.9202733485193622 recall:  0.8523206751054853 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  105 tp:  606\n",
      "train Loss: 0.1283 Acc: 0.9452\n",
      "acc:  tensor(0.8755) f1:  0.8210526315789473 recall:  0.7722772277227723 precision:  0.8764044943820225\n",
      "tn:  161 fp:  11 fn:  23 tp:  78\n",
      "val Loss: 0.4036 Acc: 0.8755\n",
      "Epoch 35/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9405) f1:  0.9128440366972477 recall:  0.8396624472573839 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  114 tp:  597\n",
      "train Loss: 0.1236 Acc: 0.9405\n",
      "acc:  tensor(0.8755) f1:  0.8229166666666666 recall:  0.7821782178217822 precision:  0.8681318681318682\n",
      "tn:  160 fp:  12 fn:  22 tp:  79\n",
      "val Loss: 0.3999 Acc: 0.8755\n",
      "Epoch 36/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9347) f1:  0.9037721324095458 recall:  0.8255977496483825 precision:  0.9982993197278912\n",
      "tn:  1203 fp:  1 fn:  124 tp:  587\n",
      "train Loss: 0.1347 Acc: 0.9347\n",
      "acc:  tensor(0.8608) f1:  0.7865168539325842 recall:  0.693069306930693 precision:  0.9090909090909091\n",
      "tn:  165 fp:  7 fn:  31 tp:  70\n",
      "val Loss: 0.4335 Acc: 0.8608\n",
      "Epoch 37/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9326) f1:  0.9005397070161911 recall:  0.8213783403656821 precision:  0.9965870307167235\n",
      "tn:  1202 fp:  2 fn:  127 tp:  584\n",
      "train Loss: 0.1326 Acc: 0.9326\n",
      "acc:  tensor(0.8645) f1:  0.7932960893854748 recall:  0.7029702970297029 precision:  0.9102564102564102\n",
      "tn:  165 fp:  7 fn:  30 tp:  71\n",
      "val Loss: 0.4441 Acc: 0.8645\n",
      "Epoch 38/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9514) f1:  0.9301277235161532 recall:  0.870604781997187 precision:  0.9983870967741936\n",
      "tn:  1203 fp:  1 fn:  92 tp:  619\n",
      "train Loss: 0.1168 Acc: 0.9514\n",
      "acc:  tensor(0.8608) f1:  0.8020833333333334 recall:  0.7623762376237624 precision:  0.8461538461538461\n",
      "tn:  158 fp:  14 fn:  24 tp:  77\n",
      "val Loss: 0.4254 Acc: 0.8608\n",
      "Epoch 39/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9337) f1:  0.901930501930502 recall:  0.8213783403656821 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  127 tp:  584\n",
      "train Loss: 0.1203 Acc: 0.9337\n",
      "acc:  tensor(0.8718) f1:  0.8167539267015707 recall:  0.7722772277227723 precision:  0.8666666666666667\n",
      "tn:  160 fp:  12 fn:  23 tp:  78\n",
      "val Loss: 0.4192 Acc: 0.8718\n",
      "Epoch 40/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9436) f1:  0.9178082191780821 recall:  0.8481012658227848 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  108 tp:  603\n",
      "train Loss: 0.1218 Acc: 0.9436\n",
      "acc:  tensor(0.8755) f1:  0.826530612244898 recall:  0.801980198019802 precision:  0.8526315789473684\n",
      "tn:  158 fp:  14 fn:  20 tp:  81\n",
      "val Loss: 0.4222 Acc: 0.8755\n",
      "Epoch 41/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9358) f1:  0.9056024558710667 recall:  0.829817158931083 precision:  0.9966216216216216\n",
      "tn:  1202 fp:  2 fn:  121 tp:  590\n",
      "train Loss: 0.1300 Acc: 0.9358\n",
      "acc:  tensor(0.8791) f1:  0.8253968253968254 recall:  0.7722772277227723 precision:  0.8863636363636364\n",
      "tn:  162 fp:  10 fn:  23 tp:  78\n",
      "val Loss: 0.4182 Acc: 0.8791\n",
      "Epoch 42/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9462) f1:  0.9221466364323508 recall:  0.8579465541490858 precision:  0.9967320261437909\n",
      "tn:  1202 fp:  2 fn:  101 tp:  610\n",
      "train Loss: 0.1219 Acc: 0.9462\n",
      "acc:  tensor(0.8681) f1:  0.8085106382978724 recall:  0.7524752475247525 precision:  0.8735632183908046\n",
      "tn:  161 fp:  11 fn:  25 tp:  76\n",
      "val Loss: 0.4233 Acc: 0.8681\n",
      "Epoch 43/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9363) f1:  0.9061538461538461 recall:  0.8284106891701828 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  122 tp:  589\n",
      "train Loss: 0.1243 Acc: 0.9363\n",
      "acc:  tensor(0.8645) f1:  0.7932960893854748 recall:  0.7029702970297029 precision:  0.9102564102564102\n",
      "tn:  165 fp:  7 fn:  30 tp:  71\n",
      "val Loss: 0.4560 Acc: 0.8645\n",
      "Epoch 44/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9467) f1:  0.9227272727272727 recall:  0.8565400843881856 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  102 tp:  609\n",
      "train Loss: 0.1230 Acc: 0.9467\n",
      "acc:  tensor(0.8755) f1:  0.8191489361702128 recall:  0.7623762376237624 precision:  0.8850574712643678\n",
      "tn:  162 fp:  10 fn:  24 tp:  77\n",
      "val Loss: 0.4234 Acc: 0.8755\n",
      "Epoch 45/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9384) f1:  0.9095092024539877 recall:  0.8340365682137834 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  118 tp:  593\n",
      "train Loss: 0.1210 Acc: 0.9384\n",
      "acc:  tensor(0.8791) f1:  0.8374384236453202 recall:  0.8415841584158416 precision:  0.8333333333333334\n",
      "tn:  155 fp:  17 fn:  16 tp:  85\n",
      "val Loss: 0.4164 Acc: 0.8791\n",
      "Epoch 46/74\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "acc:  tensor(0.9478) f1:  0.9243570347957639 recall:  0.8593530239099859 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  100 tp:  611\n",
      "train Loss: 0.1202 Acc: 0.9478\n",
      "acc:  tensor(0.8791) f1:  0.8307692307692307 recall:  0.801980198019802 precision:  0.8617021276595744\n",
      "tn:  159 fp:  13 fn:  20 tp:  81\n",
      "val Loss: 0.4076 Acc: 0.8791\n",
      "Epoch 47/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9410) f1:  0.9145880574452003 recall:  0.8509142053445851 precision:  0.988562091503268\n",
      "tn:  1197 fp:  7 fn:  106 tp:  605\n",
      "train Loss: 0.1188 Acc: 0.9410\n",
      "acc:  tensor(0.8681) f1:  0.8043478260869565 recall:  0.7326732673267327 precision:  0.891566265060241\n",
      "tn:  163 fp:  9 fn:  27 tp:  74\n",
      "val Loss: 0.4567 Acc: 0.8681\n",
      "Epoch 48/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9394) f1:  0.9111791730474731 recall:  0.8368495077355836 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  116 tp:  595\n",
      "train Loss: 0.1259 Acc: 0.9394\n",
      "acc:  tensor(0.8681) f1:  0.8105263157894738 recall:  0.7623762376237624 precision:  0.8651685393258427\n",
      "tn:  160 fp:  12 fn:  24 tp:  77\n",
      "val Loss: 0.4353 Acc: 0.8681\n",
      "Epoch 49/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9300) f1:  0.896124031007752 recall:  0.8129395218002813 precision:  0.998272884283247\n",
      "tn:  1203 fp:  1 fn:  133 tp:  578\n",
      "train Loss: 0.1234 Acc: 0.9300\n",
      "acc:  tensor(0.8571) f1:  0.7979274611398964 recall:  0.7623762376237624 precision:  0.8369565217391305\n",
      "tn:  157 fp:  15 fn:  24 tp:  77\n",
      "val Loss: 0.4536 Acc: 0.8571\n",
      "Epoch 50/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9399) f1:  0.9120122417750574 recall:  0.8382559774964838 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  115 tp:  596\n",
      "train Loss: 0.1236 Acc: 0.9399\n",
      "acc:  tensor(0.8571) f1:  0.7821229050279329 recall:  0.693069306930693 precision:  0.8974358974358975\n",
      "tn:  164 fp:  8 fn:  31 tp:  70\n",
      "val Loss: 0.4820 Acc: 0.8571\n",
      "Epoch 51/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9446) f1:  0.9198184568835098 recall:  0.8551336146272855 precision:  0.9950900163666121\n",
      "tn:  1201 fp:  3 fn:  103 tp:  608\n",
      "train Loss: 0.1212 Acc: 0.9446\n",
      "acc:  tensor(0.8718) f1:  0.8087431693989071 recall:  0.7326732673267327 precision:  0.9024390243902439\n",
      "tn:  164 fp:  8 fn:  27 tp:  74\n",
      "val Loss: 0.4889 Acc: 0.8718\n",
      "Epoch 52/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9410) f1:  0.9136745607333843 recall:  0.8410689170182841 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  113 tp:  598\n",
      "train Loss: 0.1273 Acc: 0.9410\n",
      "acc:  tensor(0.8645) f1:  0.8121827411167514 recall:  0.7920792079207921 precision:  0.8333333333333334\n",
      "tn:  156 fp:  16 fn:  21 tp:  80\n",
      "val Loss: 0.4456 Acc: 0.8645\n",
      "Epoch 53/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9269) f1:  0.890795631825273 recall:  0.8030942334739803 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  140 tp:  571\n",
      "train Loss: 0.1300 Acc: 0.9269\n",
      "acc:  tensor(0.8791) f1:  0.823529411764706 recall:  0.7623762376237624 precision:  0.8953488372093024\n",
      "tn:  163 fp:  9 fn:  24 tp:  77\n",
      "val Loss: 0.4535 Acc: 0.8791\n",
      "Epoch 54/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9368) f1:  0.9069946195234435 recall:  0.829817158931083 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  121 tp:  590\n",
      "train Loss: 0.1279 Acc: 0.9368\n",
      "acc:  tensor(0.8645) f1:  0.8 recall:  0.7326732673267327 precision:  0.8809523809523809\n",
      "tn:  162 fp:  10 fn:  27 tp:  74\n",
      "val Loss: 0.4544 Acc: 0.8645\n",
      "Epoch 55/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9410) f1:  0.9136745607333843 recall:  0.8410689170182841 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  113 tp:  598\n",
      "train Loss: 0.1201 Acc: 0.9410\n",
      "acc:  tensor(0.8718) f1:  0.8309178743961353 recall:  0.8514851485148515 precision:  0.8113207547169812\n",
      "tn:  152 fp:  20 fn:  15 tp:  86\n",
      "val Loss: 0.4855 Acc: 0.8718\n",
      "Epoch 56/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9426) f1:  0.9165402124430956 recall:  0.849507735583685 precision:  0.9950576606260296\n",
      "tn:  1201 fp:  3 fn:  107 tp:  604\n",
      "train Loss: 0.1157 Acc: 0.9426\n",
      "acc:  tensor(0.8755) f1:  0.8247422680412373 recall:  0.7920792079207921 precision:  0.8602150537634409\n",
      "tn:  159 fp:  13 fn:  21 tp:  80\n",
      "val Loss: 0.4485 Acc: 0.8755\n",
      "Epoch 57/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9368) f1:  0.9069946195234435 recall:  0.829817158931083 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  121 tp:  590\n",
      "train Loss: 0.1245 Acc: 0.9368\n",
      "acc:  tensor(0.8718) f1:  0.8108108108108107 recall:  0.7425742574257426 precision:  0.8928571428571429\n",
      "tn:  163 fp:  9 fn:  26 tp:  75\n",
      "val Loss: 0.4725 Acc: 0.8718\n",
      "Epoch 58/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9504) f1:  0.928517682468021 recall:  0.8677918424753868 precision:  0.9983818770226537\n",
      "tn:  1203 fp:  1 fn:  94 tp:  617\n",
      "train Loss: 0.1111 Acc: 0.9504\n",
      "acc:  tensor(0.8681) f1:  0.8144329896907216 recall:  0.7821782178217822 precision:  0.8494623655913979\n",
      "tn:  158 fp:  14 fn:  22 tp:  79\n",
      "val Loss: 0.4670 Acc: 0.8681\n",
      "Epoch 59/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9457) f1:  0.9210925644916541 recall:  0.8537271448663853 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  104 tp:  607\n",
      "train Loss: 0.1109 Acc: 0.9457\n",
      "acc:  tensor(0.8681) f1:  0.8064516129032258 recall:  0.7425742574257426 precision:  0.8823529411764706\n",
      "tn:  162 fp:  10 fn:  26 tp:  75\n",
      "val Loss: 0.4634 Acc: 0.8681\n",
      "Epoch 60/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9363) f1:  0.9061538461538461 recall:  0.8284106891701828 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  122 tp:  589\n",
      "train Loss: 0.1217 Acc: 0.9363\n",
      "acc:  tensor(0.8681) f1:  0.8105263157894738 recall:  0.7623762376237624 precision:  0.8651685393258427\n",
      "tn:  160 fp:  12 fn:  24 tp:  77\n",
      "val Loss: 0.4513 Acc: 0.8681\n",
      "Epoch 61/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9368) f1:  0.9069946195234435 recall:  0.829817158931083 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  121 tp:  590\n",
      "train Loss: 0.1162 Acc: 0.9368\n",
      "acc:  tensor(0.8791) f1:  0.8253968253968254 recall:  0.7722772277227723 precision:  0.8863636363636364\n",
      "tn:  162 fp:  10 fn:  23 tp:  78\n",
      "val Loss: 0.4659 Acc: 0.8791\n",
      "Epoch 62/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9358) f1:  0.905311778290993 recall:  0.8270042194092827 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  123 tp:  588\n",
      "train Loss: 0.1241 Acc: 0.9358\n",
      "acc:  tensor(0.8791) f1:  0.8272251308900525 recall:  0.7821782178217822 precision:  0.8777777777777778\n",
      "tn:  161 fp:  11 fn:  22 tp:  79\n",
      "val Loss: 0.4433 Acc: 0.8791\n",
      "Epoch 63/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9363) f1:  0.9061538461538461 recall:  0.8284106891701828 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  122 tp:  589\n",
      "train Loss: 0.1168 Acc: 0.9363\n",
      "acc:  tensor(0.8791) f1:  0.8307692307692307 recall:  0.801980198019802 precision:  0.8617021276595744\n",
      "tn:  159 fp:  13 fn:  20 tp:  81\n",
      "val Loss: 0.4755 Acc: 0.8791\n",
      "Epoch 64/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9399) f1:  0.9124143183549124 recall:  0.8424753867791842 precision:  0.9950166112956811\n",
      "tn:  1201 fp:  3 fn:  112 tp:  599\n",
      "train Loss: 0.1164 Acc: 0.9399\n",
      "acc:  tensor(0.8791) f1:  0.8253968253968254 recall:  0.7722772277227723 precision:  0.8863636363636364\n",
      "tn:  162 fp:  10 fn:  23 tp:  78\n",
      "val Loss: 0.4593 Acc: 0.8791\n",
      "Epoch 65/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9373) f1:  0.9079754601226994 recall:  0.8326300984528833 precision:  0.9983136593591906\n",
      "tn:  1203 fp:  1 fn:  119 tp:  592\n",
      "train Loss: 0.1207 Acc: 0.9373\n",
      "acc:  tensor(0.8864) f1:  0.8342245989304812 recall:  0.7722772277227723 precision:  0.9069767441860465\n",
      "tn:  164 fp:  8 fn:  23 tp:  78\n",
      "val Loss: 0.4621 Acc: 0.8864\n",
      "Epoch 66/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9379) f1:  0.908672294704528 recall:  0.8326300984528833 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  119 tp:  592\n",
      "train Loss: 0.1160 Acc: 0.9379\n",
      "acc:  tensor(0.8681) f1:  0.8085106382978724 recall:  0.7524752475247525 precision:  0.8735632183908046\n",
      "tn:  161 fp:  11 fn:  25 tp:  76\n",
      "val Loss: 0.4496 Acc: 0.8681\n",
      "Epoch 67/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9420) f1:  0.9153318077803204 recall:  0.8438818565400844 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  111 tp:  600\n",
      "train Loss: 0.1107 Acc: 0.9420\n",
      "acc:  tensor(0.8681) f1:  0.8125 recall:  0.7722772277227723 precision:  0.8571428571428571\n",
      "tn:  159 fp:  13 fn:  23 tp:  78\n",
      "val Loss: 0.4546 Acc: 0.8681\n",
      "Epoch 68/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9337) f1:  0.9020817270624518 recall:  0.8227848101265823 precision:  0.9982935153583617\n",
      "tn:  1203 fp:  1 fn:  126 tp:  585\n",
      "train Loss: 0.1138 Acc: 0.9337\n",
      "acc:  tensor(0.8755) f1:  0.8210526315789473 recall:  0.7722772277227723 precision:  0.8764044943820225\n",
      "tn:  161 fp:  11 fn:  23 tp:  78\n",
      "val Loss: 0.4770 Acc: 0.8755\n",
      "Epoch 69/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9368) f1:  0.9069946195234435 recall:  0.829817158931083 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  121 tp:  590\n",
      "train Loss: 0.1157 Acc: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  tensor(0.8864) f1:  0.835978835978836 recall:  0.7821782178217822 precision:  0.8977272727272727\n",
      "tn:  163 fp:  9 fn:  22 tp:  79\n",
      "val Loss: 0.4634 Acc: 0.8864\n",
      "Epoch 70/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9342) f1:  0.9029275808936825 recall:  0.8241912798874824 precision:  0.9982964224872232\n",
      "tn:  1203 fp:  1 fn:  125 tp:  586\n",
      "train Loss: 0.1132 Acc: 0.9342\n",
      "acc:  tensor(0.8645) f1:  0.8082901554404146 recall:  0.7722772277227723 precision:  0.8478260869565217\n",
      "tn:  158 fp:  14 fn:  23 tp:  78\n",
      "val Loss: 0.4992 Acc: 0.8645\n",
      "Epoch 71/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9431) f1:  0.916984006092917 recall:  0.8466947960618847 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  109 tp:  602\n",
      "train Loss: 0.1140 Acc: 0.9431\n",
      "acc:  tensor(0.8645) f1:  0.8042328042328043 recall:  0.7524752475247525 precision:  0.8636363636363636\n",
      "tn:  160 fp:  12 fn:  25 tp:  76\n",
      "val Loss: 0.5028 Acc: 0.8645\n",
      "Epoch 72/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9352) f1:  0.9047619047619048 recall:  0.8284106891701828 precision:  0.9966159052453468\n",
      "tn:  1202 fp:  2 fn:  122 tp:  589\n",
      "train Loss: 0.1063 Acc: 0.9352\n",
      "acc:  tensor(0.8718) f1:  0.8087431693989071 recall:  0.7326732673267327 precision:  0.9024390243902439\n",
      "tn:  164 fp:  8 fn:  27 tp:  74\n",
      "val Loss: 0.5375 Acc: 0.8718\n",
      "Epoch 73/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9420) f1:  0.9153318077803204 recall:  0.8438818565400844 precision:  1.0\n",
      "tn:  1204 fp:  0 fn:  111 tp:  600\n",
      "train Loss: 0.1208 Acc: 0.9420\n",
      "acc:  tensor(0.8755) f1:  0.8191489361702128 recall:  0.7623762376237624 precision:  0.8850574712643678\n",
      "tn:  162 fp:  10 fn:  24 tp:  77\n",
      "val Loss: 0.4863 Acc: 0.8755\n",
      "Epoch 74/74\n",
      "----------\n",
      "train\n",
      "acc:  tensor(0.9321) f1:  0.8996913580246914 recall:  0.819971870604782 precision:  0.9965811965811966\n",
      "tn:  1202 fp:  2 fn:  128 tp:  583\n",
      "train Loss: 0.1224 Acc: 0.9321\n",
      "acc:  tensor(0.8681) f1:  0.8064516129032258 recall:  0.7425742574257426 precision:  0.8823529411764706\n",
      "tn:  162 fp:  10 fn:  26 tp:  75\n",
      "val Loss: 0.5383 Acc: 0.8681\n",
      "Training complete in 28m 6s\n",
      "Best val f1: 0.840000\n",
      "Best epoch: 33.000000\n",
      "Tiempo de entrenamiento: 1686.2621076107025 segundos\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion=nn.BCELoss() \n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, train_loader, valid_loader, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Tiempo de entrenamiento: {} segundos\".format(execution_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e84cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Feature extraction-----#\n",
    "model_ft.eval()\n",
    "# Variable global para almacenar las caracter√≠sticas\n",
    "features = None\n",
    "\n",
    "# Hook para capturar las caracter√≠sticas de la √∫ltima capa convolucional\n",
    "def hook_fn(module, input, output):\n",
    "    global features\n",
    "    features = output\n",
    "    \n",
    "layer4 = model_ft.features[-1]\n",
    "hook = layer4.register_forward_hook(hook_fn)    \n",
    "\n",
    "\n",
    "# Almacenar caracter√≠sticas y etiquetas\n",
    "data = []\n",
    "# Iterar sobre el conjunto de datos y extraer caracter√≠sticas\n",
    "for inputs, labels in train_feat_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model_ft(inputs)  \n",
    "    # Convertir las caracter√≠sticas a una lista\n",
    "    flattened_features = features.view(features.size(0), -1).cpu().numpy().tolist()\n",
    "    # A√±adir las caracter√≠sticas y la etiqueta a los datos\n",
    "    data.append(flattened_features[0] + [labels.item()])\n",
    "    \n",
    "\n",
    "# Eliminar el hook para no afectar futuras operaciones\n",
    "hook.remove()\n",
    "\n",
    "# Crear un DataFrame con las caracter√≠sticas y etiquetas\n",
    "df = pd.DataFrame(data)\n",
    "# Nombres de las columnas (las caracter√≠sticas m√°s la etiqueta)\n",
    "column_names = [f'feature_{i}' for i in range(len(data[0]) - 1)] + ['label']\n",
    "df.columns = column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7c25176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_50167</th>\n",
       "      <th>feature_50168</th>\n",
       "      <th>feature_50169</th>\n",
       "      <th>feature_50170</th>\n",
       "      <th>feature_50171</th>\n",
       "      <th>feature_50172</th>\n",
       "      <th>feature_50173</th>\n",
       "      <th>feature_50174</th>\n",
       "      <th>feature_50175</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "      <td>1915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>...</td>\n",
       "      <td>3.221826</td>\n",
       "      <td>2.834019</td>\n",
       "      <td>0.906368</td>\n",
       "      <td>1.222971</td>\n",
       "      <td>1.251836</td>\n",
       "      <td>1.071717</td>\n",
       "      <td>1.709797</td>\n",
       "      <td>2.319097</td>\n",
       "      <td>1.816041</td>\n",
       "      <td>0.371279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>2.753690</td>\n",
       "      <td>2.279102</td>\n",
       "      <td>1.197044</td>\n",
       "      <td>1.505164</td>\n",
       "      <td>1.566256</td>\n",
       "      <td>1.524850</td>\n",
       "      <td>1.912584</td>\n",
       "      <td>2.038939</td>\n",
       "      <td>1.675916</td>\n",
       "      <td>0.483273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072152</td>\n",
       "      <td>1.134026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060681</td>\n",
       "      <td>0.731950</td>\n",
       "      <td>0.506039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>...</td>\n",
       "      <td>2.710081</td>\n",
       "      <td>2.409494</td>\n",
       "      <td>0.485805</td>\n",
       "      <td>0.721340</td>\n",
       "      <td>0.772037</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>1.182960</td>\n",
       "      <td>1.973718</td>\n",
       "      <td>1.467412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>...</td>\n",
       "      <td>4.662485</td>\n",
       "      <td>4.050955</td>\n",
       "      <td>1.356785</td>\n",
       "      <td>1.925339</td>\n",
       "      <td>1.948627</td>\n",
       "      <td>1.667226</td>\n",
       "      <td>2.640308</td>\n",
       "      <td>3.314453</td>\n",
       "      <td>2.662333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>...</td>\n",
       "      <td>16.067053</td>\n",
       "      <td>14.868319</td>\n",
       "      <td>9.812912</td>\n",
       "      <td>11.335787</td>\n",
       "      <td>11.967279</td>\n",
       "      <td>14.584314</td>\n",
       "      <td>11.834485</td>\n",
       "      <td>11.987537</td>\n",
       "      <td>10.223947</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 50177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0    feature_1    feature_2    feature_3    feature_4  \\\n",
       "count  1915.000000  1915.000000  1915.000000  1915.000000  1915.000000   \n",
       "mean      0.000543     0.000979     0.000563     0.000360     0.000552   \n",
       "std       0.000622     0.000660     0.000530     0.000456     0.000496   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000441     0.000027     0.000000     0.000080   \n",
       "50%       0.000348     0.000952     0.000482     0.000169     0.000473   \n",
       "75%       0.000923     0.001438     0.000897     0.000605     0.000889   \n",
       "max       0.003268     0.003373     0.003071     0.003335     0.002678   \n",
       "\n",
       "         feature_5    feature_6    feature_7    feature_8    feature_9  ...  \\\n",
       "count  1915.000000  1915.000000  1915.000000  1915.000000  1915.000000  ...   \n",
       "mean      0.000727     0.000480     0.000825     0.000842     0.000440  ...   \n",
       "std       0.000647     0.000616     0.000647     0.000573     0.000463  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000109     0.000000     0.000283     0.000404     0.000000  ...   \n",
       "50%       0.000641     0.000224     0.000777     0.000792     0.000320  ...   \n",
       "75%       0.001147     0.000804     0.001240     0.001211     0.000736  ...   \n",
       "max       0.003993     0.003590     0.003438     0.003673     0.002355  ...   \n",
       "\n",
       "       feature_50167  feature_50168  feature_50169  feature_50170  \\\n",
       "count    1915.000000    1915.000000    1915.000000    1915.000000   \n",
       "mean        3.221826       2.834019       0.906368       1.222971   \n",
       "std         2.753690       2.279102       1.197044       1.505164   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         1.072152       1.134026       0.000000       0.000000   \n",
       "50%         2.710081       2.409494       0.485805       0.721340   \n",
       "75%         4.662485       4.050955       1.356785       1.925339   \n",
       "max        16.067053      14.868319       9.812912      11.335787   \n",
       "\n",
       "       feature_50171  feature_50172  feature_50173  feature_50174  \\\n",
       "count    1915.000000    1915.000000    1915.000000    1915.000000   \n",
       "mean        1.251836       1.071717       1.709797       2.319097   \n",
       "std         1.566256       1.524850       1.912584       2.038939   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.060681       0.731950   \n",
       "50%         0.772037       0.426230       1.182960       1.973718   \n",
       "75%         1.948627       1.667226       2.640308       3.314453   \n",
       "max        11.967279      14.584314      11.834485      11.987537   \n",
       "\n",
       "       feature_50175        label  \n",
       "count    1915.000000  1915.000000  \n",
       "mean        1.816041     0.371279  \n",
       "std         1.675916     0.483273  \n",
       "min         0.000000     0.000000  \n",
       "25%         0.506039     0.000000  \n",
       "50%         1.467412     0.000000  \n",
       "75%         2.662333     1.000000  \n",
       "max        10.223947     1.000000  \n",
       "\n",
       "[8 rows x 50177 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7be761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----EVALUACION----#\n",
    "model_ft.eval()\n",
    "# Variable global para almacenar las caracter√≠sticas\n",
    "features = None\n",
    "\n",
    "# Hook para capturar las caracter√≠sticas de la √∫ltima capa convolucional\n",
    "def hook_fn(module, input, output):\n",
    "    global features\n",
    "    features = output\n",
    "    \n",
    "# Registrar el hook en la √∫ltima capa convolucional (en ResNet es 'layer4')\n",
    "layer4 = model_ft.features[-1]\n",
    "hook = layer4.register_forward_hook(hook_fn)    \n",
    "\n",
    "\n",
    "# Almacenar caracter√≠sticas y etiquetas\n",
    "data = []\n",
    "# Iterar sobre el conjunto de datos y extraer caracter√≠sticas\n",
    "for inputs, labels in valid_feat_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model_ft(inputs)  \n",
    "    # Convertir las caracter√≠sticas a una lista\n",
    "    flattened_features = features.view(features.size(0), -1).cpu().numpy().tolist()\n",
    "    # A√±adir las caracter√≠sticas y la etiqueta a los datos\n",
    "    data.append(flattened_features[0] + [labels.item()])\n",
    "    \n",
    "\n",
    "# Eliminar el hook para no afectar futuras operaciones\n",
    "hook.remove()\n",
    "\n",
    "# Crear un DataFrame con las caracter√≠sticas y etiquetas\n",
    "df = pd.DataFrame(data)\n",
    "# Nombres de las columnas (las caracter√≠sticas m√°s la etiqueta)\n",
    "column_names = [f'feature_{i}' for i in range(len(data[0]) - 1)] + ['label']\n",
    "df.columns = column_names\n",
    "if feature_extract == True:\n",
    "    df.to_csv(\"/home/calculo3/Documents/Jupyter/featurescnn_ML/pretrained_cnn_features/retrain/\"+str(archivo)+\"_valid.csv\", index=True)\n",
    "else:\n",
    "    df.to_csv(\"/home/calculo3/Documents/Jupyter/featurescnn_ML/pretrained_cnn_features/transf_learn/\"+str(archivo)+\"_valid.csv\", index=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca316b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_acc_history, label = 'train_acc') #Azul\n",
    "plt.plot(train_loss_history, label = 'train_loss')\n",
    "plt.plot(val_loss_history, label = 'val_loss')\n",
    "plt.plot(val_acc_history, label = 'val_acc') #Naranja\n",
    "#plt.plot(val_recall_history, label = 'val_recall') #verde\n",
    "#plt.plot(val_f1_history, label = 'val_f1') #rojo\n",
    "#plt.plot(train_f1_history, label = 'val_f1') #violeta\n",
    "plt.legend()\n",
    "plt.savefig(\"/home/calculo3/Documents/Jupyter/DeepLearning_pruebas/Results/entrenamiento/\"+str(archivo)+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8ab1b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1.]) tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1.])\n",
      "acc:  tensor(0.8729) f1:  0.7228915662650603 recall:  0.7142857142857143 precision:  0.7317073170731707\n",
      "tn:  128 fp:  11 fn:  12 tp:  30\n",
      "128 11 12 30\n",
      "[0.         0.07913669 1.        ] [0.         0.71428571 1.        ]\n",
      "auc 0.8175745118191162\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "TEST_DIR = \"/home/calculo3/Documents/DOCTORADO/Datasets/Dataset_2clases_DA/test\"\n",
    "\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "# Load data and create dataloaders\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=TEST_DIR, transform=data_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "test_feat_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "preds_all = torch.tensor([],dtype = torch.float32)\n",
    "labels_all = torch.tensor([],dtype = torch.float32)\n",
    "preds_all = preds_all.to(\"cpu\")\n",
    "labels_all = labels_all.to(\"cpu\")\n",
    "testSteps = 1\n",
    "model_ft.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model_ft(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    #print (\"y'\",outputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    #print(\"preds\", preds)\n",
    "    preds = preds.to(\"cpu\")\n",
    "    labels = labels.to(\"cpu\")\n",
    "    #print(\"label\", labels)\n",
    "    preds_all = torch.cat((preds_all, preds), 0)\n",
    "    labels_all = torch.cat((labels_all, labels), 0)\n",
    "  \n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "acc_val = binary_acc(preds_all, labels_all)\n",
    "f1_val = f1score(preds_all, labels_all)\n",
    "precision_val = precision(preds_all, labels_all)\n",
    "recall_val = recall(preds_all, labels_all, True)\n",
    "print(\"todo\",labels_all, preds_all)\n",
    "tn, fp, fn, tp = confusion_matrix(labels_all, preds_all).ravel()\n",
    "print(\"acc: \", acc_val, \"f1: \", f1_val, \"recall: \", recall_val, \"precision: \", precision_val)\n",
    "print(\"tn: \", tn, \"fp: \", fp, \"fn: \", fn, \"tp: \", tp)\n",
    "    \n",
    "epoch_loss = running_loss / len(test_loader.dataset)\n",
    "epoch_acc = running_corrects.double() / len(test_loader.dataset)\n",
    "print('{} Loss: {:.4f} Acc: {:.4f}'.format(\"test\", epoch_loss, epoch_acc))    \n",
    "tn, fp, fn, tp = confusion_matrix(labels_all, preds_all).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "plt.subplot(122)\n",
    "fpr, tpr, thresholds = roc_curve(labels_all, preds_all,pos_label = 1.)\n",
    "\n",
    "print(fpr, tpr)\n",
    "auc = roc_auc_score(labels_all, preds_all)\n",
    "plt.title('ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label = \"Random (AUC = 50%)\")\n",
    "plt.plot(fpr, tpr, label='CNN (AUC = {:.2f}%)'.format(auc*100))\n",
    "plt.ylabel('True Positive Rate', size=14)\n",
    "plt.legend(loc='best')\n",
    "print(\"auc\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbb6a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()\n",
    "# Variable global para almacenar las caracter√≠sticas\n",
    "features = None\n",
    "\n",
    "# Hook para capturar las caracter√≠sticas de la √∫ltima capa convolucional\n",
    "def hook_fn(module, input, output):\n",
    "    global features\n",
    "    features = output\n",
    "    \n",
    "# Registrar el hook en la √∫ltima capa convolucional (en ResNet es 'layer4')\n",
    "layer4 = model_ft.features[-1]\n",
    "hook = layer4.register_forward_hook(hook_fn)   \n",
    "\n",
    "# Almacenar caracter√≠sticas y etiquetas\n",
    "data = []\n",
    "# Iterar sobre el conjunto de datos y extraer caracter√≠sticas\n",
    "for inputs, labels in test_feat_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.no_grad():\n",
    "        _ = model_ft(inputs)  \n",
    "    # Convertir las caracter√≠sticas a una lista\n",
    "    flattened_features = features.view(features.size(0), -1).cpu().numpy().tolist()\n",
    "    # A√±adir las caracter√≠sticas y la etiqueta a los datos\n",
    "    data.append(flattened_features[0] + [labels.item()])\n",
    "    \n",
    "\n",
    "# Eliminar el hook para no afectar futuras operaciones\n",
    "hook.remove()\n",
    "\n",
    "# Crear un DataFrame con las caracter√≠sticas y etiquetas\n",
    "df = pd.DataFrame(data)\n",
    "# Nombres de las columnas (las caracter√≠sticas m√°s la etiqueta)\n",
    "column_names = [f'feature_{i}' for i in range(len(data[0]) - 1)] + ['label']\n",
    "df.columns = column_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
